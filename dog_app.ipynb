{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "GwYdmmSe8tRo",
    "outputId": "6f15c41d-d976-49fa-80e7-ff7aa1ad4a04"
   },
   "outputs": [],
   "source": [
    "# to read files from google drive, in case you're running on colab\n",
    "'''from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)'''\n",
    "data_dir = 'path to the project directory'\n",
    "# using the following repo to detect faces\n",
    "!pip3 install face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lHCJvtRj8pJY"
   },
   "source": [
    "##  Import Datasets\n",
    "\n",
    "Make sure that you've downloaded the required human and dog datasets:\n",
    "* Download the [dog dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip).  Unzip the folder and place it in this project's home directory, at the location `/dog_images`. \n",
    "\n",
    "* Download the [human dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip).  Unzip the folder and place it in the home directory, at location `/lfw`.  \n",
    "\n",
    "In the code cell below, we save the file paths for both the human (LFW) dataset and dog dataset in the numpy arrays `human_files` and `dog_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 997480
    },
    "colab_type": "code",
    "id": "FALfPUpzSrxI",
    "outputId": "a391739d-ed66-4720-f90e-05741db08065"
   },
   "outputs": [],
   "source": [
    "# download the datasets and extract the zip files\n",
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip\n",
    "!unzip dogImages.zip -d dog_images\n",
    "!mv dog_images/dogImages/* dog_images/\n",
    "!rm -r dog_images/dogImages\n",
    "!unzip lfw.zip\n",
    "!rm -f dogImages.zip lfw.zip\n",
    "!rm -r __MACOSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "2AhxAJQX8pJm",
    "outputId": "fc027dbe-743c-48fb-dee9-c41100ca8b9d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# load filenames for human and dog images\n",
    "human_files = np.array(glob(\"lfw/*/*\"))\n",
    "dog_files = np.array(glob(\"dog_images/*/*/*\"))\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total human images.' % len(human_files))\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kFgNx408pJx"
   },
   "outputs": [],
   "source": [
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n",
    "\n",
    "import face_recognition\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLpHcBKG8pJ4"
   },
   "source": [
    "### Write a Human Face Detector\n",
    "\n",
    "We can use this procedure to write a function that returns `True` if a human face is detected in an image and `False` otherwise.  This function, aptly named `face_detector`, takes a string-valued file path to an image as input and appears in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1sWPDKP8pJ5"
   },
   "outputs": [],
   "source": [
    "# returns \"True\" if face is detected in image stored at img_path.\n",
    "def face_detector(img_path):\n",
    "    image = face_recognition.load_image_file(img_path)\n",
    "    face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "    return len(face_locations) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "K0lpnrE18pJ_",
    "outputId": "c81d7491-0c93-49f2-ad0d-870ec04a8d8d"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "human_files_short = human_files[:100]\n",
    "dog_files_short = dog_files[:100]\n",
    "\n",
    "## Test the performance of the face_detector algorithm \n",
    "## on the images in human_files_short and dog_files_short.\n",
    "humans_detected_1 = 0\n",
    "for each_link in human_files_short:\n",
    "    if face_detector(each_link):\n",
    "        humans_detected_1 += 1\n",
    "        \n",
    "humans_detected_2 = 0\n",
    "for each_link in dog_files_short:\n",
    "    if face_detector(each_link):\n",
    "        humans_detected_2 += 1\n",
    "        \n",
    "print(humans_detected_1, humans_detected_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_loHJJS28pKa"
   },
   "source": [
    "### (IMPLEMENTATION) Making Predictions with a Pre-trained Model\n",
    "\n",
    "In the next code cell, you will write a function that accepts a path to an image (such as `'dogImages/train/001.Affenpinscher/Affenpinscher_00001.jpg'`) as input and returns the index corresponding to the ImageNet class that is predicted by the pre-trained resnet152 model.  The output should always be an integer between 0 and 999, inclusive.\n",
    "\n",
    "Before writing the function, make sure that you take the time to learn  how to appropriately pre-process tensors for pre-trained models in the [PyTorch documentation](http://pytorch.org/docs/stable/torchvision/models.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOoqpTUW8pLS"
   },
   "outputs": [],
   "source": [
    "### Write data loaders for training, validation, and test sets\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "batch_size = 64\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize(300),\n",
    "                                transforms.RandomRotation(5),\n",
    "                                transforms.RandomCrop(224),\n",
    "                                transforms.RandomHorizontalFlip(0.1),\n",
    "                                transforms.RandomVerticalFlip(0.1),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "valid_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('dog_images/train', transform=train_transforms)\n",
    "valid_dataset = datasets.ImageFolder('dog_images/valid', transform=valid_transforms)\n",
    "test_dataset = datasets.ImageFolder('dog_images/test', transform=valid_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size)\n",
    "\n",
    "loaders = {'train': train_loader, 'valid': valid_loader, 'test': test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9S0RUmP8pKh"
   },
   "source": [
    "### (IMPLEMENTATION) Write a Dog Detector\n",
    "\n",
    "While looking at the [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a), you will notice that the categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268, inclusive, to include all categories from `'Chihuahua'` to `'Mexican hairless'`.  Thus, in order to check to see if an image is predicted to contain a dog by the pre-trained VGG-16 model, we need only check if the pre-trained model predicts an index between 151 and 268 (inclusive).\n",
    "\n",
    "Use these ideas to complete the `dog_detector` function below, which returns `True` if a dog is detected in an image (and `False` if not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GtwCdYE8pKr"
   },
   "source": [
    "### (IMPLEMENTATION) Assess the Dog Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YUh3ToQJfRx"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES=True\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path, usingSGD=True):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            \n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "                # move to GPU\n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                ## update the average validation loss\n",
    "                outputs = model(data)\n",
    "                \n",
    "                loss = criterion(outputs, target)\n",
    "                valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "         \n",
    "        if(usingSGD):\n",
    "            lr_scheduler.step(valid_loss_min)\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## save the model if validation loss has decreased\n",
    "        if(valid_loss < valid_loss_min):\n",
    "            valid_loss_min = valid_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuVxHmO2rY50"
   },
   "outputs": [],
   "source": [
    "# use transfer learning to train vgg16 for higher accuracy at detecting dogs\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "vgg16_transfer = models.vgg16(pretrained=True)\n",
    "for param in vgg16_transfer.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "classifier_name, old_classifier = vgg16_transfer._modules.popitem()\n",
    "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(old_classifier[0].in_features, 4096)),\n",
    "                                        ('relu1', nn.ReLU()),\n",
    "                                        ('drop1', nn.Dropout(0.7)),\n",
    "                                        ('fc2', nn.Linear(4096, 4096)),\n",
    "                                        ('relu2', nn.ReLU()),\n",
    "                                        ('drop2', nn.Dropout(0.5)),\n",
    "                                        ('output', nn.Linear(4096, 1))\n",
    "                                           ]))\n",
    "vgg16_transfer.add_module(classifier_name, classifier)\n",
    "#print(vgg16_transfer)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    vgg16_transfer = vgg16_transfer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-3AijPvWGtd"
   },
   "outputs": [],
   "source": [
    "# specifying loss function and optimizer\n",
    "loss_dog = lambda output, _ : torch.mean((output-1)**2) \n",
    "optimizer_dog = optim.Adam(vgg16_transfer.parameters(), lr=0.000001)\n",
    "\n",
    "# train the model\n",
    "vgg16_transfer = train(10, loaders, vgg16_transfer, optimizer_dog, loss_dog, use_cuda, 'model_dog.pt', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2A1RIKRfTDw"
   },
   "outputs": [],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "vgg16_transfer.load_state_dict(torch.load(data_dir+'saved_models/model_dog.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epyAudhX8pKb"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def VGG16_predict(img_path):\n",
    "    '''   \n",
    "    Args:\n",
    "        img_path: path to an image\n",
    "        \n",
    "    Returns:\n",
    "        Index corresponding to resnet152 model's prediction\n",
    "    '''\n",
    "    \n",
    "    ## Load and pre-process an image from the given img_path\n",
    "    ## Return the *index* of the predicted class for that image\n",
    "    image = Image.open(img_path)\n",
    "    t1 = transforms.RandomResizedCrop(224)\n",
    "    t2 = transforms.ToTensor()\n",
    "    t3 = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    image = t1(image)\n",
    "    image = t2(image)\n",
    "    image = t3(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    if use_cuda:\n",
    "        image = image.cuda()\n",
    "    #print(image.shape)\n",
    "    vgg16_transfer.eval()\n",
    "    output = vgg16_transfer(image)\n",
    "        \n",
    "    #print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d1UyaJtL8pKk"
   },
   "outputs": [],
   "source": [
    "### returns \"True\" if a dog is detected in the image stored at img_path\n",
    "def dog_detector(img_path):\n",
    "    output = VGG16_predict(img_path)\n",
    "    #print(output)\n",
    "    return output > 0.5 # true/false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "L9MW3YBI8pKt",
    "outputId": "720e3e99-e464-467c-cc8f-de464ab08eed"
   },
   "outputs": [],
   "source": [
    "### Test the performance of the dog_detector function\n",
    "### on the images in human_files_short and dog_files_short.\n",
    "dogs_detected = 0\n",
    "for pic in human_files_short:\n",
    "    if dog_detector(pic):\n",
    "        dogs_detected += 1\n",
    "print(dogs_detected, 'dogs detected in', len(human_files_short), 'human images')\n",
    "\n",
    "dogs_detected = 0\n",
    "for pic in dog_files_short:\n",
    "    if dog_detector(pic):\n",
    "        dogs_detected += 1\n",
    "print(dogs_detected, 'dogs detected in', len(dog_files_short), 'dog images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zbjjqne98pL8"
   },
   "source": [
    "## Create a CNN to Classify Dog Breeds (using Transfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmKtIqL08pMM"
   },
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Use transfer learning to create a CNN to classify dog breed.  Use the code cell below, and save your initialized model as the variable `model_transfer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDhTbs1L8pMO"
   },
   "outputs": [],
   "source": [
    "model_transfer = models.resnet152(pretrained=True)\n",
    "# uncomment the following to freeze the pre-trained layers\n",
    "'''ct = 0\n",
    "layer_to_freeze = 7\n",
    "for child in model_transfer.children():\n",
    "    ct += 1\n",
    "    if ct < layer_to_freeze:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False'''\n",
    "    \n",
    "classifier_name, old_classifier = model_transfer._modules.popitem()\n",
    "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(old_classifier.in_features, 133))]))\n",
    "model_transfer.add_module(classifier_name, classifier)\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()\n",
    "#model_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVv1sCGt8pMh"
   },
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/master/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/master/optim.html).  Save the chosen loss function as `criterion_transfer`, and the optimizer as `optimizer_transfer` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XyVrRQ28pMj"
   },
   "outputs": [],
   "source": [
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.SGD(model_transfer.fc.parameters(), 0.09, momentum = 0.9)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_transfer, mode='min', factor=0.1, patience=2)\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0zJpPsD8pM6"
   },
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_transfer.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "vGktXGZ38pM8",
    "outputId": "51b53bbf-ca20-4ec1-c70e-d04cc0afce82"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "model_transfer = train(n_epochs, loaders, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRhh5xtK8pNG"
   },
   "outputs": [],
   "source": [
    "# load the model that got the best validation accuracy (uncomment the line below)\n",
    "model_transfer.load_state_dict(torch.load(data_dir+'saved_models/model_transfer_89.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "colab_type": "code",
    "id": "gsHtLZgCt3Yy",
    "outputId": "2974275d-f445-4ff9-f93d-485b346db256"
   },
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average test loss \n",
    "            test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "            # convert output probabilities to predicted class\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            # compare predictions to true label\n",
    "            correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# call test function    \n",
    "test(loaders, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vpq7XwVG8pNl"
   },
   "source": [
    "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
    "\n",
    "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan hound`, etc) that is predicted by your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E13mO2np8pNt"
   },
   "outputs": [],
   "source": [
    "### A function that takes a path to an image as input\n",
    "### and returns the dog breed that is psredicted by the model.\n",
    "\n",
    "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in train_dataset.classes]\n",
    "\n",
    "def predict_breed_transfer(img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    global model_transfer\n",
    "    image = Image.open(img_path)\n",
    "    t1 = transforms.Resize(256)\n",
    "    t2 = transforms.CenterCrop(224)\n",
    "    t3 = transforms.ToTensor()\n",
    "    t4 = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    image = t4(t3(t2(t1(image))))\n",
    "    image = image.unsqueeze(0)\n",
    "    if(use_cuda):\n",
    "        image = image.cuda()\n",
    "        model_transfer = model_transfer.cuda()\n",
    "    #print('lol what\\'s happening')\n",
    "    model_transfer.eval()\n",
    "    output_list = model_transfer(image).tolist()[0]\n",
    "    #print(output_list)\n",
    "    max_value = max(output_list)\n",
    "        \n",
    "    #print(output)\n",
    "    return class_names[output_list.index(max_value)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JBfPGosr8pNz"
   },
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## The Algorithm\n",
    "\n",
    "Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
    "- if a __dog__ is detected in the image, return the predicted breed.\n",
    "- if a __human__ is detected in the image, return the resembling dog breed.\n",
    "- if __neither__ is detected in the image, provide output that indicates an error.\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Write your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ctSVtzlw8pN1"
   },
   "outputs": [],
   "source": [
    "def run_app(img_path):\n",
    "    ## handle cases for a human face, dog, and neither\n",
    "    img = cv2.imread(img_path)\n",
    "    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb)\n",
    "    plt.show()\n",
    "    \n",
    "    if dog_detector(img_path) and not face_detector(img_path):\n",
    "        print(\"You have been visited by the good luck bringing doggo, your lucky breed is...\\n\", predict_breed_transfer(img_path))\n",
    "        \n",
    "    elif face_detector(img_path):\n",
    "        print(\"Aaaaand your spirit animal is...\\n\", predict_breed_transfer(img_path))\n",
    "    else:\n",
    "        print(\"bruh! with right data comes right output, without, error messages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4Hp_fwj8pN8"
   },
   "source": [
    "### (IMPLEMENTATION) Test the Algorithm on Sample Images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yy1bGWdP8pN_"
   },
   "outputs": [],
   "source": [
    "for file in np.hstack((human_files[69:72], dog_files[69:72])):\n",
    "    run_app(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3207
    },
    "colab_type": "code",
    "id": "Ol4i0GHo8pOK",
    "outputId": "4e807f89-8491-4319-8e99-ac41bbe9dba4"
   },
   "outputs": [],
   "source": [
    "#testing the algorithm on images from my pc\n",
    "local_images = os.listdir(data_dir+'local_images')\n",
    "for each_image in local_images:\n",
    "    if not each_image.startswith('.'):\n",
    "        run_app(data_dir+'local_images/'+each_image)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dog_app.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
